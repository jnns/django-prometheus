{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"django-prometheus Export Django monitoring metrics for Prometheus.io Usage Requirements Django >= 1.11 Installation Install with: pip install django-prometheus Or, if you're using a development version cloned from this repository: python path-to-where-you-cloned-django-prometheus/setup.py install This will install prometheus_client as a dependency. Quickstart In your settings.py: INSTALLED_APPS = ( ... 'django_prometheus' , ... ) MIDDLEWARE = ( 'django_prometheus.middleware.PrometheusBeforeMiddleware' , # All your other middlewares go here, including the default # middlewares like SessionMiddleware, CommonMiddleware, # CsrfViewmiddleware, SecurityMiddleware, etc. 'django_prometheus.middleware.PrometheusAfterMiddleware' , ) In your urls.py: urlpatterns = [ ... url ( '' , include ( 'django_prometheus.urls' )), ] Configuration Prometheus uses Histogram based grouping for monitoring latencies. The default buckets are here: https://github.com/prometheus/client_python/blob/master/prometheus_client/core.py You can define custom buckets for latency, adding more buckets decreases performance but increases accuracy: https://prometheus.io/docs/practices/histograms/ PROMETHEUS_LATENCY_BUCKETS = ( . 01 , . 025 , . 05 , . 075 , . 1 , . 25 , . 5 , . 75 , 1.0 , 2.5 , 5.0 , 7.5 , 10.0 , 25.0 , 50.0 , 75.0 , float ( \"inf\" ), ) Monitoring your databases SQLite, MySQL, and PostgreSQL databases can be monitored. Just replace the ENGINE property of your database, replacing django.db.backends with django_prometheus.db.backends . DATABASES = { 'default' : { 'ENGINE' : 'django_prometheus.db.backends.sqlite3' , 'NAME' : os . path . join ( BASE_DIR , 'db.sqlite3' ), }, } Monitoring your caches Filebased, memcached, redis caches can be monitored. Just replace the cache backend to use the one provided by django_prometheus django.core.cache.backends with django_prometheus.cache.backends . CACHES = { 'default' : { 'BACKEND' : 'django_prometheus.cache.backends.filebased.FileBasedCache' , 'LOCATION' : '/var/tmp/django_cache' , } } Monitoring your models You may want to monitor the creation/deletion/update rate for your model. This can be done by adding a mixin to them. This is safe to do on existing models (it does not require a migration). If your model is: class Dog ( models . Model ): name = models . CharField ( max_length = 100 , unique = True ) breed = models . CharField ( max_length = 100 , blank = True , null = True ) age = models . PositiveIntegerField ( blank = True , null = True ) Just add the ExportModelOperationsMixin as such: from django_prometheus.models import ExportModelOperationsMixin class Dog ( ExportModelOperationsMixin ( 'dog' ), models . Model ): name = models . CharField ( max_length = 100 , unique = True ) breed = models . CharField ( max_length = 100 , blank = True , null = True ) age = models . PositiveIntegerField ( blank = True , null = True ) This will export 3 metrics, django_model_inserts_total{model=\"dog\"} , django_model_updates_total{model=\"dog\"} and django_model_deletes_total{model=\"dog\"} . Note Note that the exported metrics are counters of creations, modifications and deletions done in the current process. They are not gauges of the number of objects in the model. Starting with Django 1.7, migrations are also monitored. Two gauges are exported, django_migrations_applied_by_connection and django_migrations_unapplied_by_connection . You may want to alert if there are unapplied migrations. If you want to disable the Django migration metrics, set the PROMETHEUS_EXPORT_MIGRATIONS setting to False . Monitoring and aggregating the metrics Prometheus is quite easy to set up. An example prometheus.conf to scrape 127.0.0.1:8001 can be found in examples/prometheus . Here's an example of a PromDash displaying some of the metrics collected by django-prometheus: Adding your own metrics You can add application-level metrics in your code by using prometheus_client directly. The exporter is global and will pick up your metrics. To add metrics to the Django internals, the easiest way is to extend django-prometheus' classes. Please consider contributing your metrics, pull requests are welcome. Make sure to read the Prometheus best practices on instrumentation and naming . Importing Django Prometheus using only local settings If you wish to use Django Prometheus but are not able to change the code base, it's possible to have all the default metrics by modifying only the settings. First step is to inject prometheus' middlewares and to add django_prometheus in INSTALLED_APPS MIDDLEWARE = ( ( 'django_prometheus.middleware.PrometheusBeforeMiddleware' ,) + MIDDLEWARE + ( 'django_prometheus.middleware.PrometheusAfterMiddleware' ,) ) INSTALLED_APPS = INSTALLED_APPS + ( 'django_prometheus' ,) Second step is to create the /metrics endpoint, for that we need another file (called urls_prometheus_wrapper.py in this example) that will wrap the app's URLs and add one on top: from django.conf.urls import include , url urlpatterns = [] urlpatterns . append ( url ( '^prometheus/' , include ( 'django_prometheus.urls' ))) urlpatterns . append ( url ( '' , include ( 'myapp.urls' ))) This file will add a /prometheus/metrics endpoint to the URLs of Django that will export the metrics (replace myapp by your project name). Then we inject the wrapper in settings: ROOT_URLCONF = \"graphite.urls_prometheus_wrapper\" Adding custom labels to middleware (request/response) metrics You can add application specific labels to metrics reported by the django-prometheus middleware. This involves extending the classes defined in middleware.py . Extend the Metrics class and override the register_metric method to add the application specific labels. Extend MIDDLEWARE , set the metrics_cls class attribute to the the extended metric class and override the label_metric method to attach custom metrics. See implementation example in the test app .","title":"Usage"},{"location":"#django-prometheus","text":"Export Django monitoring metrics for Prometheus.io","title":"django-prometheus"},{"location":"#usage","text":"","title":"Usage"},{"location":"#requirements","text":"Django >= 1.11","title":"Requirements"},{"location":"#installation","text":"Install with: pip install django-prometheus Or, if you're using a development version cloned from this repository: python path-to-where-you-cloned-django-prometheus/setup.py install This will install prometheus_client as a dependency.","title":"Installation"},{"location":"#quickstart","text":"In your settings.py: INSTALLED_APPS = ( ... 'django_prometheus' , ... ) MIDDLEWARE = ( 'django_prometheus.middleware.PrometheusBeforeMiddleware' , # All your other middlewares go here, including the default # middlewares like SessionMiddleware, CommonMiddleware, # CsrfViewmiddleware, SecurityMiddleware, etc. 'django_prometheus.middleware.PrometheusAfterMiddleware' , ) In your urls.py: urlpatterns = [ ... url ( '' , include ( 'django_prometheus.urls' )), ]","title":"Quickstart"},{"location":"#configuration","text":"Prometheus uses Histogram based grouping for monitoring latencies. The default buckets are here: https://github.com/prometheus/client_python/blob/master/prometheus_client/core.py You can define custom buckets for latency, adding more buckets decreases performance but increases accuracy: https://prometheus.io/docs/practices/histograms/ PROMETHEUS_LATENCY_BUCKETS = ( . 01 , . 025 , . 05 , . 075 , . 1 , . 25 , . 5 , . 75 , 1.0 , 2.5 , 5.0 , 7.5 , 10.0 , 25.0 , 50.0 , 75.0 , float ( \"inf\" ), )","title":"Configuration"},{"location":"#monitoring-your-databases","text":"SQLite, MySQL, and PostgreSQL databases can be monitored. Just replace the ENGINE property of your database, replacing django.db.backends with django_prometheus.db.backends . DATABASES = { 'default' : { 'ENGINE' : 'django_prometheus.db.backends.sqlite3' , 'NAME' : os . path . join ( BASE_DIR , 'db.sqlite3' ), }, }","title":"Monitoring your databases"},{"location":"#monitoring-your-caches","text":"Filebased, memcached, redis caches can be monitored. Just replace the cache backend to use the one provided by django_prometheus django.core.cache.backends with django_prometheus.cache.backends . CACHES = { 'default' : { 'BACKEND' : 'django_prometheus.cache.backends.filebased.FileBasedCache' , 'LOCATION' : '/var/tmp/django_cache' , } }","title":"Monitoring your caches"},{"location":"#monitoring-your-models","text":"You may want to monitor the creation/deletion/update rate for your model. This can be done by adding a mixin to them. This is safe to do on existing models (it does not require a migration). If your model is: class Dog ( models . Model ): name = models . CharField ( max_length = 100 , unique = True ) breed = models . CharField ( max_length = 100 , blank = True , null = True ) age = models . PositiveIntegerField ( blank = True , null = True ) Just add the ExportModelOperationsMixin as such: from django_prometheus.models import ExportModelOperationsMixin class Dog ( ExportModelOperationsMixin ( 'dog' ), models . Model ): name = models . CharField ( max_length = 100 , unique = True ) breed = models . CharField ( max_length = 100 , blank = True , null = True ) age = models . PositiveIntegerField ( blank = True , null = True ) This will export 3 metrics, django_model_inserts_total{model=\"dog\"} , django_model_updates_total{model=\"dog\"} and django_model_deletes_total{model=\"dog\"} . Note Note that the exported metrics are counters of creations, modifications and deletions done in the current process. They are not gauges of the number of objects in the model. Starting with Django 1.7, migrations are also monitored. Two gauges are exported, django_migrations_applied_by_connection and django_migrations_unapplied_by_connection . You may want to alert if there are unapplied migrations. If you want to disable the Django migration metrics, set the PROMETHEUS_EXPORT_MIGRATIONS setting to False .","title":"Monitoring your models"},{"location":"#monitoring-and-aggregating-the-metrics","text":"Prometheus is quite easy to set up. An example prometheus.conf to scrape 127.0.0.1:8001 can be found in examples/prometheus . Here's an example of a PromDash displaying some of the metrics collected by django-prometheus:","title":"Monitoring and aggregating the metrics"},{"location":"#adding-your-own-metrics","text":"You can add application-level metrics in your code by using prometheus_client directly. The exporter is global and will pick up your metrics. To add metrics to the Django internals, the easiest way is to extend django-prometheus' classes. Please consider contributing your metrics, pull requests are welcome. Make sure to read the Prometheus best practices on instrumentation and naming .","title":"Adding your own metrics"},{"location":"#importing-django-prometheus-using-only-local-settings","text":"If you wish to use Django Prometheus but are not able to change the code base, it's possible to have all the default metrics by modifying only the settings. First step is to inject prometheus' middlewares and to add django_prometheus in INSTALLED_APPS MIDDLEWARE = ( ( 'django_prometheus.middleware.PrometheusBeforeMiddleware' ,) + MIDDLEWARE + ( 'django_prometheus.middleware.PrometheusAfterMiddleware' ,) ) INSTALLED_APPS = INSTALLED_APPS + ( 'django_prometheus' ,) Second step is to create the /metrics endpoint, for that we need another file (called urls_prometheus_wrapper.py in this example) that will wrap the app's URLs and add one on top: from django.conf.urls import include , url urlpatterns = [] urlpatterns . append ( url ( '^prometheus/' , include ( 'django_prometheus.urls' ))) urlpatterns . append ( url ( '' , include ( 'myapp.urls' ))) This file will add a /prometheus/metrics endpoint to the URLs of Django that will export the metrics (replace myapp by your project name). Then we inject the wrapper in settings: ROOT_URLCONF = \"graphite.urls_prometheus_wrapper\"","title":"Importing Django Prometheus using only local settings"},{"location":"#adding-custom-labels-to-middleware-requestresponse-metrics","text":"You can add application specific labels to metrics reported by the django-prometheus middleware. This involves extending the classes defined in middleware.py . Extend the Metrics class and override the register_metric method to add the application specific labels. Extend MIDDLEWARE , set the metrics_cls class attribute to the the extended metric class and override the label_metric method to attach custom metrics. See implementation example in the test app .","title":"Adding custom labels to middleware (request/response) metrics"},{"location":"CHANGELOG/","text":"Changelog v2.0.0 - Jan 20, 2020 Added support for newer Django and Python versions Added an extensibility that applications to add their own labels to middleware (request/response) metrics Allow overriding and setting custom bucket values for request/response latency histogram metric Internal improvements: use tox Use pytest use Black Automate pre-releases on every commit ot master Fix flaky tests. v1.1.0 - Sep 28, 2019 maintenance release that updates this library to support recent and supported version of python & Django","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#v200-jan-20-2020","text":"Added support for newer Django and Python versions Added an extensibility that applications to add their own labels to middleware (request/response) metrics Allow overriding and setting custom bucket values for request/response latency histogram metric Internal improvements: use tox Use pytest use Black Automate pre-releases on every commit ot master Fix flaky tests.","title":"v2.0.0 - Jan 20, 2020"},{"location":"CHANGELOG/#v110-sep-28-2019","text":"maintenance release that updates this library to support recent and supported version of python & Django","title":"v1.1.0 -  Sep 28, 2019"},{"location":"CONTRIBUTING/","text":"Contributing Git Feel free to send pull requests, even for the tiniest things. Watch for Travis' opinion on them ( ). Travis will also make sure your code is pep8 compliant, and it's a good idea to run flake8 as well (on django_prometheus/ and on tests/). The code contains \"unused\" imports on purpose so flake8 isn't run automatically. Tests Please write unit tests for your change. There are two kinds of tests: Regular unit tests that test the code directly, without loading Django. This is limited to pieces of the code that don't depend on Django, since a lot of the Django code will require a full Django environment (anything that interacts with models, for instance, needs a full database configuration). End-to-end tests are Django unit tests in a test application. The test application doubles as an easy way to interactively test your changes. It uses most of the basic Django features and a few advanced features, so you can test things for yourself. Running all tests python setup.py test cd tests/end2end/ && PYTHONPATH = ../.. ./manage.py test The former runs the regular unit tests, the latter runs the Django unit test. To avoid setting PYTHONPATH every time, you can also run python setup.py install . Running the test Django app cd tests/end2end/ && PYTHONPATH = ../.. ./manage.py runserver By default, this will start serving on http://localhost:8000/. Metrics are available at /metrics . Running Prometheus See http://prometheus.io/docs/ for instructions on installing Prometheus. Once you have Prometheus installed, you can use the example rules and dashboard in examples/prometheus/ . See examples/prometheus/README.md to run Prometheus and view the example dashboard.","title":"Contributing"},{"location":"CONTRIBUTING/#contributing","text":"","title":"Contributing"},{"location":"CONTRIBUTING/#git","text":"Feel free to send pull requests, even for the tiniest things. Watch for Travis' opinion on them ( ). Travis will also make sure your code is pep8 compliant, and it's a good idea to run flake8 as well (on django_prometheus/ and on tests/). The code contains \"unused\" imports on purpose so flake8 isn't run automatically.","title":"Git"},{"location":"CONTRIBUTING/#tests","text":"Please write unit tests for your change. There are two kinds of tests: Regular unit tests that test the code directly, without loading Django. This is limited to pieces of the code that don't depend on Django, since a lot of the Django code will require a full Django environment (anything that interacts with models, for instance, needs a full database configuration). End-to-end tests are Django unit tests in a test application. The test application doubles as an easy way to interactively test your changes. It uses most of the basic Django features and a few advanced features, so you can test things for yourself.","title":"Tests"},{"location":"CONTRIBUTING/#running-all-tests","text":"python setup.py test cd tests/end2end/ && PYTHONPATH = ../.. ./manage.py test The former runs the regular unit tests, the latter runs the Django unit test. To avoid setting PYTHONPATH every time, you can also run python setup.py install .","title":"Running all tests"},{"location":"CONTRIBUTING/#running-the-test-django-app","text":"cd tests/end2end/ && PYTHONPATH = ../.. ./manage.py runserver By default, this will start serving on http://localhost:8000/. Metrics are available at /metrics .","title":"Running the test Django app"},{"location":"CONTRIBUTING/#running-prometheus","text":"See http://prometheus.io/docs/ for instructions on installing Prometheus. Once you have Prometheus installed, you can use the example rules and dashboard in examples/prometheus/ . See examples/prometheus/README.md to run Prometheus and view the example dashboard.","title":"Running Prometheus"},{"location":"exports/","text":"Exports Default: exporting /metrics as a Django view /metrics can be exported as a Django view very easily. Simply include('django_prometheus.urls') with no prefix like so: urlpatterns = [ ... url ( '' , include ( 'django_prometheus.urls' )), ] This will reserve the /metrics path on your server. This may be a problem for you, so you can use a prefix. For instance, the following will export the metrics at /monitoring/metrics instead. You will need to configure Prometheus to use that path instead of the default. urlpatterns = [ ... url ( '^monitoring/' , include ( 'django_prometheus.urls' )), ] Exporting /metrics in a dedicated thread To ensure that issues in your Django app do not affect the monitoring, it is recommended to export /metrics in an HTTPServer running in a daemon thread. This will prevent that problems such as thread starvation or low-level bugs in Django do not affect the export of your metrics, which may be more needed than ever if these problems occur. It can be enabled by adding the following line in your settings.py : PROMETHEUS_METRICS_EXPORT_PORT = 8001 PROMETHEUS_METRICS_EXPORT_ADDRESS = '' # all addresses However, by default this mechanism is disabled, because it is not compatible with Django's autoreloader. The autoreloader is the feature that allows you to edit your code and see the changes immediately. This works by forking multiple processes of Django, which would compete for the port. As such, this code will assert-fail if the autoreloader is active. You can run Django without the autoreloader by passing -noreload to manage.py . If you decide to enable the thread-based exporter in production, you may wish to modify your manage.py to ensure that this option is always active: execute_from_command_line ( sys . argv + [ '--noreload' ]) Exporting /metrics in a WSGI application with multiple processes per process If you're using WSGI (e.g. with uwsgi or with gunicorn) and multiple Django processes, using either option above won't work, as requests using the Django view would just go to an inconsistent backend each time, and exporting on a single port doesn't work. The following settings can be used instead: PROMETHEUS_METRICS_EXPORT_PORT_RANGE = range ( 8001 , 8050 ) This will make Django-Prometheus try to export /metrics on port 8001. If this fails (i.e. the port is in use), it will try 8002, then 8003, etc. You can then configure Prometheus to collect metrics on as many targets as you have workers, using each port separately. Exporting /metrics in a WSGI application with multiple processes globally In some WSGI applications, workers are short lived (less than a minute), so some are never scraped by prometheus by default. Prometheus client already provides a nice system to aggregate them using the env variable: prometheus_multiproc_dir which will configure the directory where metrics will be stored as files per process. Configuration in uwsgi would look like: env = prometheus_multiproc_dir=/path/to/django_metrics You can also set this environment variable elsewhere such as in a kubernetes manifest. Note that the environment variable is lower_case. Setting this will create four files (one for counters, one for summaries, ...etc) for each pid used. In uwsgi, the number of different pids used can be quite large (the pid change every time a worker respawn). To prevent having thousand of files created, it's possible to create file using worker ids rather than pids. You can change the function used for identifying the process to use the uwsgi worker_id. Modify this in settings before any metrics are created: try : import prometheus_client import uwsgi prometheus_client . values . ValueClass = prometheus_client . values . MultiProcessValue ( _pidFunc = uwsgi . worker_id ) except ImportError : pass # not running in uwsgi Note that this code uses internal interfaces of prometheus_client. The underlying implementation may change. The number of resulting files will be: number of processes * 4 (counter, histogram, gauge, summary) Be aware that by default this will generate a large amount of file descriptors: Each worker will keep 3 file descriptors for each files it created. Since these files will be written often, you should consider mounting this directory as a tmpfs or using a subdir of an existing one such as /run/ or /var/run/ . If uwsgi is not using lazy-apps (lazy-apps = true), there will be a file descriptors leak (tens to hundreds of fds on a single file) due to the way uwsgi forks processes to create workers.","title":"Exports"},{"location":"exports/#exports","text":"","title":"Exports"},{"location":"exports/#default-exporting-metrics-as-a-django-view","text":"/metrics can be exported as a Django view very easily. Simply include('django_prometheus.urls') with no prefix like so: urlpatterns = [ ... url ( '' , include ( 'django_prometheus.urls' )), ] This will reserve the /metrics path on your server. This may be a problem for you, so you can use a prefix. For instance, the following will export the metrics at /monitoring/metrics instead. You will need to configure Prometheus to use that path instead of the default. urlpatterns = [ ... url ( '^monitoring/' , include ( 'django_prometheus.urls' )), ]","title":"Default: exporting /metrics as a Django view"},{"location":"exports/#exporting-metrics-in-a-dedicated-thread","text":"To ensure that issues in your Django app do not affect the monitoring, it is recommended to export /metrics in an HTTPServer running in a daemon thread. This will prevent that problems such as thread starvation or low-level bugs in Django do not affect the export of your metrics, which may be more needed than ever if these problems occur. It can be enabled by adding the following line in your settings.py : PROMETHEUS_METRICS_EXPORT_PORT = 8001 PROMETHEUS_METRICS_EXPORT_ADDRESS = '' # all addresses However, by default this mechanism is disabled, because it is not compatible with Django's autoreloader. The autoreloader is the feature that allows you to edit your code and see the changes immediately. This works by forking multiple processes of Django, which would compete for the port. As such, this code will assert-fail if the autoreloader is active. You can run Django without the autoreloader by passing -noreload to manage.py . If you decide to enable the thread-based exporter in production, you may wish to modify your manage.py to ensure that this option is always active: execute_from_command_line ( sys . argv + [ '--noreload' ])","title":"Exporting /metrics in a dedicated thread"},{"location":"exports/#exporting-metrics-in-a-wsgi-application-with-multiple-processes-per-process","text":"If you're using WSGI (e.g. with uwsgi or with gunicorn) and multiple Django processes, using either option above won't work, as requests using the Django view would just go to an inconsistent backend each time, and exporting on a single port doesn't work. The following settings can be used instead: PROMETHEUS_METRICS_EXPORT_PORT_RANGE = range ( 8001 , 8050 ) This will make Django-Prometheus try to export /metrics on port 8001. If this fails (i.e. the port is in use), it will try 8002, then 8003, etc. You can then configure Prometheus to collect metrics on as many targets as you have workers, using each port separately.","title":"Exporting /metrics in a WSGI application with multiple processes per process"},{"location":"exports/#exporting-metrics-in-a-wsgi-application-with-multiple-processes-globally","text":"In some WSGI applications, workers are short lived (less than a minute), so some are never scraped by prometheus by default. Prometheus client already provides a nice system to aggregate them using the env variable: prometheus_multiproc_dir which will configure the directory where metrics will be stored as files per process. Configuration in uwsgi would look like: env = prometheus_multiproc_dir=/path/to/django_metrics You can also set this environment variable elsewhere such as in a kubernetes manifest. Note that the environment variable is lower_case. Setting this will create four files (one for counters, one for summaries, ...etc) for each pid used. In uwsgi, the number of different pids used can be quite large (the pid change every time a worker respawn). To prevent having thousand of files created, it's possible to create file using worker ids rather than pids. You can change the function used for identifying the process to use the uwsgi worker_id. Modify this in settings before any metrics are created: try : import prometheus_client import uwsgi prometheus_client . values . ValueClass = prometheus_client . values . MultiProcessValue ( _pidFunc = uwsgi . worker_id ) except ImportError : pass # not running in uwsgi Note that this code uses internal interfaces of prometheus_client. The underlying implementation may change. The number of resulting files will be: number of processes * 4 (counter, histogram, gauge, summary) Be aware that by default this will generate a large amount of file descriptors: Each worker will keep 3 file descriptors for each files it created. Since these files will be written often, you should consider mounting this directory as a tmpfs or using a subdir of an existing one such as /run/ or /var/run/ . If uwsgi is not using lazy-apps (lazy-apps = true), there will be a file descriptors leak (tens to hundreds of fds on a single file) due to the way uwsgi forks processes to create workers.","title":"Exporting /metrics in a WSGI application with multiple processes globally"}]}